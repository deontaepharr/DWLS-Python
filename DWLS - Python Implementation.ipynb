{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from quadprog import solve_qp #https://pypi.org/project/quadprog/ || installed with conda -- look into how/what || #dual method of Goldfarb and Idnani (1982, 1983) for solving quadratic programming problems of the form \n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def perform_ols(sig_mat, bulk_sample):\n",
    "    # NOTES:\n",
    "    # S = signature matrix ==> sig_mat\n",
    "    # B = Bulk data individual sample ==> bulk_sample\n",
    "    # sol = OLS initial weights ==> ols_weights\n",
    "    sigsig_dot = sig_mat.T.dot(sig_mat).values #D=G\n",
    "    sigbulk_dot = sig_mat.T.dot(bulk_sample).values #d=a\n",
    "    sig_eye_mat = np.identity(sig_mat.shape[1]) #A=C\n",
    "    sig_zeros_mat = np.array([0.0] * sig_mat.shape[1]) #b=x ; TODO: lookup the purpose? ; also must be float: https://stackoverflow.com/questions/36510859/cvxopt-qp-solver-typeerror-a-must-be-a-d-matrix-with-1000-columns\n",
    "    qprog_sol = solve_qp(G=sigsig_dot, a=sigbulk_dot, C=sig_eye_mat, b=sig_zeros_mat, meq=0, factorized=False)\n",
    "    qprog_sol = qprog_sol[0] #gets the solution\n",
    "    qprog_sol = pd.DataFrame(qprog_sol, index=sig_mat.columns) #convert to dataframe, with cell type as index\n",
    "    \n",
    "    return qprog_sol\n",
    "\n",
    "def find_dampening_constant(sig_mat, bulk_sample, ols_weights, epochs=100):\n",
    "    ws = (1/sig_mat.dot(ols_weights)).pow(2)\n",
    "    ws_scaled = ws/ws.min()\n",
    "    ws_val = int(np.ceil(np.log2(ws_scaled.loc[ws_scaled[0] != np.inf, 0].max())))\n",
    "\n",
    "    solutions_std_list = []\n",
    "    for j in range(ws_val):\n",
    "        multiplier = np.power(2, j)\n",
    "        ws_dampened = ws_scaled.copy()\n",
    "        ws_dampened.loc[ws_dampened[0] > multiplier, 0] = multiplier\n",
    "        \n",
    "        solutions = []\n",
    "        for i in range(epochs):\n",
    "            np.random.seed(i)\n",
    "            n=int(ws_dampened.shape[0]/2)\n",
    "            subset_indices = np.random.choice(a=ws_dampened.shape[0], size=n, replace=False)\n",
    "            y = bulk_sample.iloc[subset_indices]\n",
    "            X = sig_mat.iloc[subset_indices] #Having -1 adds a constant, purpose?IDK: https://stackoverflow.com/questions/52596724/linear-regression-in-r-and-python-different-results-at-same-problem\n",
    "            w = ws_dampened.iloc[subset_indices]\n",
    "            wls_model = sm.WLS(y, X, weights=w, missing=\"raise\")\n",
    "            wls_result = wls_model.fit(method=\"qr\").params\n",
    "            wls_result = wls_result * (ols_weights.sum() / wls_result.sum()).values[0]\n",
    "            solutions.append(wls_result)\n",
    "\n",
    "\n",
    "        solutions_std = pd.concat(solutions, axis=1).std(axis=1)\n",
    "        solutions_std = solutions_std.rename(j+1) #rename to dampening constant (multiplier)+1\n",
    "        solutions_std_list.append(solutions_std)\n",
    "\n",
    "    solutions_std_df = pd.concat(solutions_std_list, axis=1)\n",
    "    dampening_constant = solutions_std_df.pow(2).mean(axis=0).idxmin() #index=dampening constant (multiplier)\n",
    "    return dampening_constant\n",
    "\n",
    "def solve_dampenedWLS_with_constant(sig_mat, bulk_sample, ols_weights, dampening_constant):\n",
    "    # NOTES:\n",
    "    # S = signature matrix ==> sig_mat\n",
    "    # B = Bulk data individual sample ==> bulk_sample\n",
    "    # sol = goldStandard = OLS initial weights ==> ols_weights\n",
    "    multiplier = 1 * np.power(2, (dampening_constant-1))\n",
    "    sol = ols_weights.copy()\n",
    "    ws = (1 / sig_mat.dot(sol)).pow(2)\n",
    "    ws_scaled = ws / ws.min()\n",
    "    ws_dampened = ws_scaled.copy()\n",
    "    ws_dampened.loc[ws_dampened[0] > multiplier, 0] = multiplier\n",
    "    W_diag = pd.DataFrame(np.diag(ws_dampened[0]),index=ws_dampened.index,columns=ws_dampened.index)\n",
    "    D = sig_mat.T.dot(W_diag).dot(sig_mat)\n",
    "    d = sig_mat.T.dot(W_diag).dot(bulk_sample)\n",
    "    sig_eye_mat = np.identity(sig_mat.shape[1]) #A\n",
    "    sig_zeros_mat = np.array([0.0] * sig_mat.shape[1]) #b=x ; TODO: lookup the purpose? ; also must be float: https://stackoverflow.com/questions/36510859/cvxopt-qp-solver-typeerror-a-must-be-a-d-matrix-with-1000-columns\n",
    "    sc = np.linalg.norm(D, ord=2) #2-norm (largest sing. value) || specifies the â€œspectralâ€ or 2-norm, which is the largest singular value (svd) of x.\n",
    "    qprog_sol = solve_qp(G=(D/sc).values, a=(d/sc).values, C=sig_eye_mat, b=sig_zeros_mat, meq=0, factorized=False)\n",
    "    qprog_sol = qprog_sol[0] #gets the solution\n",
    "    qprog_sol = pd.DataFrame(qprog_sol, index=sig_mat.columns) #convert to dataframe, with cell type as index\n",
    "    return qprog_sol\n",
    "\n",
    "def solve_dampenedWLS(sig_mat, bulk_sample):\n",
    "    ols_weights = perform_ols(sig_mat, bulk_sample)\n",
    "    dampening_constant = find_dampening_constant(sig_mat, bulk_sample, ols_weights, epochs=100)\n",
    "    iterations =0\n",
    "    changes = []\n",
    "    change = 1\n",
    "    solution = solve_dampenedWLS_with_constant(sig_mat, bulk_sample, ols_weights, dampening_constant)\n",
    "    while change>.01 and iterations<1000 : \n",
    "        new_solution = solve_dampenedWLS_with_constant(sig_mat, bulk_sample, ols_weights, dampening_constant)\n",
    "        solution_average = pd.concat([solution] + [new_solution]*4 , axis=1).mean(1)\n",
    "        change = np.linalg.norm((solution_average-solution[0]).to_frame(), ord=1)\n",
    "        solution = solution_average\n",
    "        iterations += 1\n",
    "        changes.append(change)\n",
    "        \n",
    "    return solution/solution.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USER INPUT TO DO DWLS\n",
    "signature_matrix_file_location = \"SIGNATURE MATRIX FILE LOCATION\"\n",
    "signature_matrix_delimiter ='DELIMITER'\n",
    "\n",
    "bulk_data_file_location = \"BULK DATA FILE LOCATION\"\n",
    "bulk_data_delimiter ='DELIMITER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume first column is gene markers || have a condition check in #intersection of sig and bulk data\n",
    "signature_matrix = pd.read_csv(signature_matrix_file_location, sep=signature_matrix_delimiter, index_col=0)\n",
    "signature_matrix.index = signature_matrix.index.str.upper()\n",
    "\n",
    "bulk_data = pd.read_csv(bulk_data_file_location, sep=bulk_data_delimiter, index_col=0)\n",
    "bulk_data.index = bulk_data.index.str.upper()\n",
    "\n",
    "#Filter matrices by similar genes\n",
    "sig_mat_genes = set(signature_matrix.index.str.upper())\n",
    "bulk_genes = set(bulk_data.index.str.upper())\n",
    "genes_intersecting = sig_mat_genes.intersection(bulk_genes)\n",
    "\n",
    "#Get signature matrix and get intersecting genes\n",
    "sig_mat = signature_matrix #get fresh matrix with each loop #Is this really needed, as im not changing the sig mat?\n",
    "sig_mat = sig_mat.loc[genes_intersecting]\n",
    "\n",
    "#Get bulk data with intersecting genes\n",
    "bulk_data = bulk_data.loc[genes_intersecting]\n",
    "\n",
    "dwls_solutions = Parallel(n_jobs=-1)(delayed(solve_dampenedWLS)(sig_mat, bulk_data[col]) for col in tqdm(bulk_data.columns))\n",
    "dwls_solutions = pd.concat(dwls_solutions, axis=1)\n",
    "dwls_solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
